{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft4jPsbvK-aI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Tkf1stjg6c4p"
      },
      "outputs": [],
      "source": [
        "!pip install jamo jiwer jamotools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "z1X5BG2yJqVE"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8doyOPsZgWGl"
      },
      "outputs": [],
      "source": [
        "from jamo import hangul_to_jamo\n",
        "from jamo import h2j, j2hcj\n",
        "import re\n",
        "\n",
        "def text_to_jamo(text):\n",
        "    return ''.join(j2hcj(h2j(text)))\n",
        "\n",
        "def clean_jamo_text(jamo_text):\n",
        "    return re.sub(r'[^\\u3131-\\u3163\\u1100-\\u11FF\\uAC00-\\uD7A3 ]', '', jamo_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIu2p31dgson"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, Audio\n",
        "from transformers import AutoProcessor, Wav2Vec2ForCTC, AutoModelForCTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6JFuT4q6mN0"
      },
      "outputs": [],
      "source": [
        "processor = AutoProcessor.from_pretrained(\"student-47/wav2vec2-large-xlrs-korean-v5\")\n",
        "model = AutoModelForCTC.from_pretrained(\"student-47/wav2vec2-large-xlrs-korean-v5\")\n",
        "\n",
        "config = model.config\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Gssitdfgsqq"
      },
      "outputs": [],
      "source": [
        "# Read data\n",
        "df = pd.read_csv('./labels_speech_recognition_final.csv')\n",
        "#df['audio_path'] = '../../' + df['path']\n",
        "#data = df[df['audio_path'].apply(os.path.exists)].copy()\n",
        "df['audio_path'] = './augmented/' + df['path'].astype(str) + '.wav'\n",
        "\n",
        "# Filter out rows where the audio file does not exist\n",
        "data = df[df['audio_path'].apply(os.path.exists)].copy()\n",
        "\n",
        "# Label code\n",
        "le_gender = LabelEncoder().fit(data['gender'])\n",
        "le_age = LabelEncoder().fit(data['age'])\n",
        "le_accent = LabelEncoder().fit(data['accents'])\n",
        "\n",
        "data['gender_label'] = le_gender.transform(data['gender'])\n",
        "data['age_label'] = le_age.transform(data['age'])\n",
        "data['accent_label'] = le_accent.transform(data['accents'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5nXYurDgss4"
      },
      "outputs": [],
      "source": [
        "train_val, test = train_test_split(data, test_size=0.1, random_state=47)\n",
        "train, val = train_test_split(train_val, test_size=2/9, random_state=47)\n",
        "\n",
        "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")\n",
        "\n",
        "# ====== Convert to Huggingface Dataset and preprocess ======\n",
        "train_dataset = Dataset.from_pandas(train.reset_index(drop=True))\n",
        "val_dataset = Dataset.from_pandas(val.reset_index(drop=True))\n",
        "test_dataset = Dataset.from_pandas(test.reset_index(drop=True))\n",
        "\n",
        "# NOTE: The audio path field is now audio_path\n",
        "train_dataset = train_dataset.cast_column(\"audio_path\", Audio(sampling_rate=16000))\n",
        "val_dataset = val_dataset.cast_column(\"audio_path\", Audio(sampling_rate=16000))\n",
        "test_dataset = test_dataset.cast_column(\"audio_path\", Audio(sampling_rate=16000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjf6BOZFgsvS"
      },
      "outputs": [],
      "source": [
        "MAX_AUDIO_LEN = 16000 * 10\n",
        "\n",
        "def preprocess_function(batch):\n",
        "    audio = batch[\"audio_path\"]\n",
        "    #audio_array = audio[\"array\"][:MAX_AUDIO_LEN]\n",
        "    audio_array = audio[\"array\"]\n",
        "    jamo_text = text_to_jamo(batch[\"sentence\"])\n",
        "    jamo_text = clean_jamo_text(jamo_text)\n",
        "    inputs = processor(\n",
        "        [audio_array],\n",
        "        sampling_rate=audio[\"sampling_rate\"],\n",
        "        text=[jamo_text],\n",
        "        return_tensors=\"pt\",\n",
        "        padding=\"longest\"\n",
        "    )\n",
        "\n",
        "    input_values = inputs.input_values[0]\n",
        "    attention_mask = inputs.attention_mask[0]\n",
        "    labels = inputs.labels[0]\n",
        "    return {\n",
        "        \"input_values\": input_values,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"labels\": labels,\n",
        "        \"age_label\": batch[\"age_label\"],\n",
        "        \"gender_label\": batch[\"gender_label\"],\n",
        "        \"accent_label\": batch[\"accent_label\"]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoVEoc2tgsxe"
      },
      "outputs": [],
      "source": [
        "processed_train = train_dataset.map(preprocess_function, remove_columns=train_dataset.column_names)\n",
        "processed_val = val_dataset.map(preprocess_function, remove_columns=val_dataset.column_names)\n",
        "processed_test = test_dataset.map(preprocess_function, remove_columns=test_dataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzx6qgHGgs2O"
      },
      "outputs": [],
      "source": [
        "# Data loader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_values = [torch.tensor(item['input_values']) for item in batch]\n",
        "    attention_mask = [torch.tensor(item['attention_mask']) for item in batch]\n",
        "    labels = [torch.tensor(item['labels']) for item in batch]\n",
        "    age_labels = torch.tensor([item['age_label'] for item in batch], dtype=torch.long)\n",
        "    gender_labels = torch.tensor([item['gender_label'] for item in batch], dtype=torch.long)\n",
        "    accent_labels = torch.tensor([item['accent_label'] for item in batch], dtype=torch.long)\n",
        "\n",
        "    input_values = torch.nn.utils.rnn.pad_sequence(input_values, batch_first=True)\n",
        "    attention_mask = torch.nn.utils.rnn.pad_sequence(attention_mask, batch_first=True)\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-100)\n",
        "\n",
        "    return {\n",
        "        'input_values': input_values,\n",
        "        'attention_mask': attention_mask,\n",
        "        'labels': labels,\n",
        "        'age_label': age_labels,\n",
        "        'gender_label': gender_labels,\n",
        "        'accent_label': accent_labels\n",
        "    }\n",
        "\n",
        "train_batch_size = 8\n",
        "eval_batch_size = 8\n",
        "\n",
        "train_loader = DataLoader(processed_train, batch_size=train_batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=4)\n",
        "val_loader = DataLoader(processed_val, batch_size=eval_batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True, num_workers=4)\n",
        "test_loader = DataLoader(processed_test, batch_size=eval_batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9FFIOB-gsz3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import Wav2Vec2ForCTC\n",
        "\n",
        "class MultiTaskWav2Vec2(nn.Module):\n",
        "    def __init__(self, base_model_name, num_age, num_gender, num_accent):\n",
        "        super().__init__()\n",
        "        self.asr = Wav2Vec2ForCTC.from_pretrained(\n",
        "            base_model_name,\n",
        "            # --- SpecAugment Setting ---\n",
        "            mask_time_prob=0.05,        # The fraction of time steps to which the temporal mask is applied\n",
        "            mask_time_length=10,        # The average length of each temporal mask\n",
        "            mask_feature_prob=0.05,      # The proportion of frequency channels to apply the frequency mask to\n",
        "            mask_feature_length=64,      # The average length of each frequency mask\n",
        "        )\n",
        "\n",
        "        hidden_size = self.asr.config.hidden_size\n",
        "\n",
        "        self.age_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 128), nn.ReLU(), nn.Linear(128, num_age)\n",
        "        )\n",
        "        self.gender_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 64), nn.ReLU(), nn.Linear(64, num_gender)\n",
        "        )\n",
        "        self.accent_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 128), nn.ReLU(), nn.Linear(128, num_accent)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_values, attention_mask=None):\n",
        "        outputs = self.asr.wav2vec2(input_values, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.last_hidden_state  # [B, T, H]\n",
        "        pooled = hidden_states.mean(dim=1)  # [B, H]\n",
        "        age_logits = self.age_head(pooled)\n",
        "        gender_logits = self.gender_head(pooled)\n",
        "        accent_logits = self.accent_head(pooled)\n",
        "        ctc_logits = self.asr.lm_head(hidden_states)\n",
        "        return {\n",
        "            'logits': ctc_logits,\n",
        "            'age_logits': age_logits,\n",
        "            'gender_logits': gender_logits,\n",
        "            'accent_logits': accent_logits,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz-auWfXhAeD"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import jiwer\n",
        "from jiwer import wer\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from tqdm.auto import tqdm\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhOxc_pthAh3"
      },
      "outputs": [],
      "source": [
        "def manual_compute_measures(references, predictions, show_progress=False):\n",
        "    if len(references) != len(predictions):\n",
        "        return {\n",
        "            'wer': float('inf'),\n",
        "            'substitutions': 0,\n",
        "            'deletions': 0,\n",
        "            'insertions': 0,\n",
        "            'hits': 0\n",
        "        }\n",
        "\n",
        "    total_substitutions = 0\n",
        "    total_deletions = 0\n",
        "    total_insertions = 0\n",
        "    total_hits = 0\n",
        "    total_ref_words = 0\n",
        "\n",
        "    # Decide whether to wrap the loop based on the show_progress parameter\n",
        "    # Creating a basic iterator\n",
        "    iterator = zip(references, predictions)\n",
        "    # If necessary, wrap it with tqdm\n",
        "    if show_progress:\n",
        "        iterator = tqdm(iterator, total=len(references), desc=\"Caculate WER\", unit=\"sentence\")\n",
        "\n",
        "    #for ref, hyp in zip(references, predictions):\n",
        "    for ref, hyp in iterator:\n",
        "        ref_words = ref.strip().split()\n",
        "        hyp_words = hyp.strip().split()\n",
        "\n",
        "        total_ref_words += len(ref_words)\n",
        "\n",
        "        if len(ref_words) == 0:\n",
        "            total_insertions += len(hyp_words)\n",
        "            continue\n",
        "\n",
        "        # Dynamic programming to calculate edit distance and operation type\n",
        "        d = [[0] * (len(hyp_words) + 1) for _ in range(len(ref_words) + 1)]\n",
        "\n",
        "        # Initialize Bounds\n",
        "        for i in range(len(ref_words) + 1):\n",
        "            d[i][0] = i\n",
        "        for j in range(len(hyp_words) + 1):\n",
        "            d[0][j] = j\n",
        "\n",
        "        # Filling the Matrix\n",
        "        for i in range(1, len(ref_words) + 1):\n",
        "            for j in range(1, len(hyp_words) + 1):\n",
        "                if ref_words[i-1] == hyp_words[j-1]:\n",
        "                    d[i][j] = d[i-1][j-1]       # Match, no action\n",
        "                else:\n",
        "                    d[i][j] = min(\n",
        "                        d[i-1][j] + 1,      # Delete\n",
        "                        d[i][j-1] + 1,      # Insert\n",
        "                        d[i-1][j-1] + 1      # Replace\n",
        "                    )\n",
        "\n",
        "        # Backtrack to calculate the specific number of operations\n",
        "        i, j = len(ref_words), len(hyp_words)\n",
        "        while i > 0 or j > 0:\n",
        "            if i > 0 and j > 0 and ref_words[i-1] == hyp_words[j-1]:\n",
        "                # Match\n",
        "                total_hits += 1\n",
        "                i -= 1\n",
        "                j -= 1\n",
        "            elif i > 0 and j > 0 and d[i][j] == d[i-1][j-1] + 1:\n",
        "                # Replace\n",
        "                total_substitutions += 1\n",
        "                i -= 1\n",
        "                j -= 1\n",
        "            elif i > 0 and d[i][j] == d[i-1][j] + 1:\n",
        "                # Delete\n",
        "                total_deletions += 1\n",
        "                i -= 1\n",
        "            elif j > 0 and d[i][j] == d[i][j-1] + 1:\n",
        "                # Insert\n",
        "                total_insertions += 1\n",
        "                j -= 1\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    # Calculating WER\n",
        "    wer = (total_substitutions + total_deletions + total_insertions) / total_ref_words if total_ref_words > 0 else float('inf')\n",
        "\n",
        "    return {\n",
        "        'wer': wer,\n",
        "        'substitutions': total_substitutions,\n",
        "        'deletions': total_deletions,\n",
        "        'insertions': total_insertions,\n",
        "        'hits': total_hits\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6o2t-kyhAnI"
      },
      "outputs": [],
      "source": [
        "def calculate_wer(predictions: List[str], references: List[str], show_progress: bool = False) -> dict:\n",
        "    if len(predictions) != len(references) or len(predictions) == 0:\n",
        "        return {\n",
        "            'wer': float('inf'),\n",
        "            'substitutions': 0,\n",
        "            'deletions': 0,\n",
        "            'insertions': 0,\n",
        "            'hits': 0\n",
        "        }\n",
        "\n",
        "    # Clear data\n",
        "    clean_predictions = []\n",
        "    clean_references = []\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        pred_clean = str(pred).strip() if pred is not None else \"\"\n",
        "        ref_clean = str(ref).strip() if ref is not None else \"\"\n",
        "\n",
        "        if pred_clean and ref_clean:\n",
        "            clean_predictions.append(pred_clean)\n",
        "            clean_references.append(ref_clean)\n",
        "\n",
        "    if len(clean_predictions) == 0:\n",
        "        return {\n",
        "            'wer': float('inf'),\n",
        "            'substitutions': 0,\n",
        "            'deletions': 0,\n",
        "            'insertions': 0,\n",
        "            'hits': 0\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        measures = {}\n",
        "        # Add a \"wait-style\" progress bar to jiwer\n",
        "        if show_progress:\n",
        "            with tqdm(total=1, desc=\"Use jiwer to cacluate WER\") as pbar:\n",
        "                measures = jiwer.compute_measures(clean_references, clean_predictions)\n",
        "                pbar.update(1)\n",
        "        else:\n",
        "            # If the progress bar is not displayed, the calculation is performed directly\n",
        "            measures = jiwer.compute_measures(clean_references, clean_predictions)\n",
        "        # Calculate detailed indicators\n",
        "        #measures = jiwer.compute_measures(clean_references, clean_predictions)\n",
        "\n",
        "        return {\n",
        "            'wer': measures['wer'],\n",
        "            'substitutions': measures['substitutions'],\n",
        "            'deletions': measures['deletions'],\n",
        "            'insertions': measures['insertions'],\n",
        "            'hits': measures['hits']\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"jiwer failed, using manual calculation: {e}\")\n",
        "        return manual_compute_measures(clean_references, clean_predictions, show_progress=show_progress)\n",
        "        #return manual_compute_measures(clean_references, clean_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caH1zHaXhAre"
      },
      "outputs": [],
      "source": [
        "def compute_loss(batch, outputs, processor, epoch):\n",
        "    batch_size, max_seq_len, _ = outputs['logits'].shape\n",
        "    input_lengths = torch.full(\n",
        "        size=(batch_size,),\n",
        "        fill_value=max_seq_len,\n",
        "        dtype=torch.long,\n",
        "        device=outputs['logits'].device\n",
        "    )\n",
        "    target_lengths = (batch['labels'] != -100).sum(dim=1)\n",
        "    labels_flattened = []\n",
        "    for i in range(batch_size):\n",
        "        valid = batch['labels'][i][batch['labels'][i] != -100]\n",
        "        labels_flattened.append(valid)\n",
        "    labels_flattened = torch.cat(labels_flattened)\n",
        "\n",
        "    # CTC Loss\n",
        "    ctc_loss = F.ctc_loss(\n",
        "        outputs['logits'].log_softmax(-1).transpose(0, 1),\n",
        "        labels_flattened,\n",
        "        input_lengths=input_lengths,\n",
        "        target_lengths=target_lengths,\n",
        "        blank=processor.tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "    # Classification Loss\n",
        "    age_loss = F.cross_entropy(outputs['age_logits'], batch['age_label'])\n",
        "    gender_loss = F.cross_entropy(outputs['gender_logits'], batch['gender_label'])\n",
        "    accent_loss = F.cross_entropy(outputs['accent_logits'], batch['accent_label'])\n",
        "\n",
        "    # Dynamic task weights\n",
        "    if 'task_weights' in outputs:\n",
        "        # Perform softmax normalization on task weights\n",
        "        task_weights = F.softmax(outputs['task_weights'], dim=0)\n",
        "\n",
        "        # Weighted auxiliary task loss\n",
        "        aux_loss = (task_weights[0] * age_loss +\n",
        "                   task_weights[1] * gender_loss +\n",
        "                   task_weights[2] * accent_loss)\n",
        "\n",
        "        # Total loss = CTC loss + weighted auxiliary loss\n",
        "        total_loss = ctc_loss + aux_loss\n",
        "\n",
        "        # Print weight information (for debugging)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Task weights - Age: {task_weights[0]:.3f}, \"\n",
        "                  f\"Gender: {task_weights[1]:.3f}, \"\n",
        "                  f\"Accent: {task_weights[2]:.3f}\")\n",
        "    else:\n",
        "        # Fixed weights as a fallback\n",
        "        total_loss = ctc_loss + 0.5 * age_loss + 0.5 * gender_loss + 0.5 * accent_loss\n",
        "\n",
        "    return total_loss, ctc_loss, age_loss, gender_loss, accent_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odaI9KsGhAwL"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, dataloader, optimizer, processor, epoch, lr_scheduler, gradient_accumulation_steps, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    step = 0\n",
        "    accumulated_step = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} Training\", unit=\"batch\")\n",
        "\n",
        "    #for batch in dataloader:\n",
        "    for batch in progress_bar:\n",
        "        torch.cuda.empty_cache()\n",
        "        step += 1\n",
        "        for k in batch:\n",
        "            if isinstance(batch[k], torch.Tensor):\n",
        "                batch[k] = batch[k].to(device)\n",
        "        outputs = model(\n",
        "            input_values=batch['input_values'],\n",
        "            attention_mask=batch['attention_mask']\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            loss, xlsr_loss, age_loss, gender_loss, accent_loss = compute_loss(batch, outputs, processor, epoch)\n",
        "                # Gradient accumulation: loss divided by the number of accumulated steps\n",
        "            loss = loss / gradient_accumulation_steps\n",
        "        except RuntimeError as e:\n",
        "            if \"Expected tensor to have size\" in str(e):\n",
        "                print(f\"Skip abnormal batch: {e}\")\n",
        "                continue\n",
        "            else: raise\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient accumulation: updated every gradient_accumulation_steps steps\n",
        "        if step % gradient_accumulation_steps == 0:\n",
        "            # Optimizer Updates\n",
        "            optimizer.step()\n",
        "\n",
        "            # Learning rate scheduler update\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            # Zero gradient\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            accumulated_step += 1\n",
        "\n",
        "        # Cumulative loss (recovering the true loss value)\n",
        "        total_loss += loss.item() * gradient_accumulation_steps\n",
        "\n",
        "    # If there are still unupdated gradients at the end\n",
        "    if step % gradient_accumulation_steps != 0:\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        accumulated_step += 1\n",
        "\n",
        "    res = total_loss / step\n",
        "\n",
        "    '''try:\n",
        "            loss, xlsr_loss, age_loss, gender_loss, accent_loss = compute_loss(batch, outputs, processor, epoch)\n",
        "        except RuntimeError as e:\n",
        "            if \"Expected tensor to have size\" in str(e):\n",
        "                print(f\"Skip abnormal batch: {e}\")\n",
        "                continue\n",
        "            else: raise\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        res = total_loss / len(dataloader)'''\n",
        "\n",
        "    return {\n",
        "        'train_loss': res,\n",
        "        'xlsr_train_loss': xlsr_loss.item(),\n",
        "        'age_train_loss': age_loss.item(),\n",
        "        'gender_train_loss': gender_loss.item(),\n",
        "        'accent_train_loss': accent_loss.item(),\n",
        "        'step': step\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA15kpVPhA1V"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, processor, epoch, device, detailed_analysis=False):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct_age, correct_gender, correct_accent = 0, 0, 0\n",
        "    total = 0\n",
        "    all_predictions, all_references = [], []\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1} Evaluation\", unit=\"batch\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        #for batch in dataloader:\n",
        "        for batch in progress_bar:\n",
        "            for k in batch:\n",
        "                if isinstance(batch[k], torch.Tensor):\n",
        "                    batch[k] = batch[k].to(device)\n",
        "            outputs = model(\n",
        "                input_values=batch['input_values'],\n",
        "                attention_mask=batch['attention_mask']\n",
        "            )\n",
        "\n",
        "            try:\n",
        "                loss, xlsr_loss, age_loss, gender_loss, accent_loss = compute_loss(batch, outputs, processor, epoch)\n",
        "            except RuntimeError as e:\n",
        "                if \"Expected tensor to have size\" in str(e):\n",
        "                    print(f\"Skip abnormal batch: {e}\")\n",
        "                    continue\n",
        "                else:\n",
        "                    raise\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct_age += (outputs['age_logits'].argmax(dim=1) == batch['age_label']).sum().item()\n",
        "            correct_gender += (outputs['gender_logits'].argmax(dim=1) == batch['gender_label']).sum().item()\n",
        "            correct_accent += (outputs['accent_logits'].argmax(dim=1) == batch['accent_label']).sum().item()\n",
        "            total += batch['age_label'].size(0)\n",
        "\n",
        "            # WER\n",
        "            pred_ids = outputs['logits'].argmax(dim=-1)\n",
        "            predictions = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "\n",
        "            labels = batch['labels'].cpu().numpy()\n",
        "            references = []\n",
        "            for label in labels:\n",
        "                label = label[label != -100]    # Remove padding\n",
        "                references.append(processor.tokenizer.decode(label, skip_special_tokens=True))\n",
        "\n",
        "            all_predictions.extend(predictions)\n",
        "            all_references.extend(references)\n",
        "\n",
        "    val_loss = total_loss / len(dataloader)\n",
        "    wer_score = calculate_wer(all_predictions, all_references)\n",
        "\n",
        "    res = {\n",
        "        'val_loss': val_loss,\n",
        "        'xlsr_val_loss': xlsr_loss.item(),\n",
        "        'age_val_loss': age_loss.item(),\n",
        "        'gender_val_loss': gender_loss.item(),\n",
        "        'accent_val_loss': accent_loss.item(),\n",
        "        'wer': wer_score['wer'],\n",
        "        'age_acc': correct_age / total,\n",
        "        'gender_acc': correct_gender / total,\n",
        "        'accent_acc': correct_accent / total\n",
        "    }\n",
        "\n",
        "    if detailed_analysis:\n",
        "        detailed_metrics = calculate_wer(all_predictions, all_references, show_progress=True)\n",
        "        res['detailed_wer'] = detailed_metrics\n",
        "\n",
        "        print(f\"\\n=== Detailed WER Analysis (Epoch {epoch+1}) ===\")\n",
        "        print(f\"WER: {detailed_metrics['wer']:.4f}\")\n",
        "        print(f\"Substitutions: {detailed_metrics['substitutions']}\")\n",
        "        print(f\"Deletions: {detailed_metrics['deletions']}\")\n",
        "        print(f\"Insertions: {detailed_metrics['insertions']}\")\n",
        "        print(f\"Hits: {detailed_metrics['hits']}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az-3y1WCgs6_"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "# ========== Start time ==========\n",
        "start_time = time.perf_counter()\n",
        "\n",
        "# ====== Train ======\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import random\n",
        "from torch.optim import Adam\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_age = len(le_age.classes_)\n",
        "num_gender = len(le_gender.classes_)\n",
        "num_accent = len(le_accent.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP0samjcgs9t"
      },
      "outputs": [],
      "source": [
        "file_path = \"./saved_model/best_model.txt\"\n",
        "save_path = \"./saved_model/best_model.pt\"\n",
        "\n",
        "model = MultiTaskWav2Vec2(\"student-47/wav2vec2-large-xlrs-korean-v5\", num_age, num_gender, num_accent)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(save_path, map_location=device))\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "lr = 0.0001\n",
        "seed = 47\n",
        "gradient_accumulation_steps = 2\n",
        "\n",
        "optimizer = Adam(\n",
        "    model.parameters(),\n",
        "    lr=lr,\n",
        "    betas=(0.9, 0.999),\n",
        "    eps=1e-08\n",
        ")\n",
        "\n",
        "lr_scheduler = LinearLR(\n",
        "    optimizer,\n",
        "    start_factor=0.1,\n",
        "    total_iters=1000\n",
        ")\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(seed)\n",
        "\n",
        "def print_shape_or_len(arr, name):\n",
        "    if hasattr(arr, 'shape'):\n",
        "        print(f\"{name} shape:\", arr.shape)\n",
        "    else:\n",
        "        print(f\"{name} len:\", len(arr))\n",
        "\n",
        "num_epochs = 13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfj2x10pgtAQ"
      },
      "outputs": [],
      "source": [
        "best_t_loss = float('inf')\n",
        "best_t_xlsr_loss = float('inf')\n",
        "best_t_age_loss = float('inf')\n",
        "best_t_gender_loss = float('inf')\n",
        "best_t_accent_loss = float('inf')\n",
        "\n",
        "best_v_loss = float('inf')\n",
        "best_v_xlsr_loss = float('inf')\n",
        "best_v_age_loss = float('inf')\n",
        "best_v_gender_loss = float('inf')\n",
        "best_v_accent_loss = float('inf')\n",
        "\n",
        "best_wer = float('inf')\n",
        "best_age_acc = 0.0\n",
        "best_gender_acc = 0.0\n",
        "best_accent_acc = 0.0\n",
        "best_epoch = 0\n",
        "best_step = 0\n",
        "\n",
        "best_metrics = {}\n",
        "\n",
        "flag = False\n",
        "is_best = False\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "\n",
        "            if not line or line.startswith('#') or line.startswith(\"'''\"): continue\n",
        "\n",
        "            if line.startswith(\"Best model at epoch\"):\n",
        "                best_epoch = float(line.split()[-1])\n",
        "            elif line.startswith(\"Train Loss:\"):\n",
        "                best_t_loss = float(line.split(\":\")[1].strip())\n",
        "            elif line.startswith(\"Xlsr Train Loss:\"):\n",
        "                best_t_xlsr_loss = float(line.split(\":\")[1].strip())\n",
        "            elif line.startswith(\"Age Train Loss:\"):\n",
        "                best_t_age_loss = float(line.split(\":\")[1].strip())\n",
        "            elif line.startswith(\"Gender Train Loss:\"):\n",
        "                best_t_gender_loss = float(line.split(\":\")[1].strip())\n",
        "            elif line.startswith(\"Accent Train Loss:\"):\n",
        "                best_t_accent_loss = float(line.split(\":\")[1].strip())\n",
        "\n",
        "            elif line.startswith(\"Val Loss:\"):\n",
        "                best_v_loss = float(line.split(\":\")[1].strip())\n",
        "            elif line.startswith(\"Xlsr Val Loss:\"):\n",
        "                best_v_xlsr_loss = float(line.split(\":\")[1].strip())\n",
        "            elif line.startswith(\"Age Val Loss:\"):\n",
        "                best_v_age_loss = float(line.split(\":\")[1].strip())\n",
        "            elif line.startswith(\"Gender Val Loss:\"):\n",
        "                best_v_gender_loss = float(line.split(\":\")[1].strip())\n",
        "            elif line.startswith(\"Accent Val Loss:\"):\n",
        "                best_v_accent_loss = float(line.split(\":\")[1].strip())\n",
        "\n",
        "            elif line.startswith(\"WER:\"):\n",
        "                best_wer = float(line.split(\":\")[1].strip())\n",
        "            elif line.startswith(\"Age Acc:\"):\n",
        "                best_age_acc = float(line.split(\":\")[1].strip())\n",
        "            elif line.startswith(\"Gender Acc:\"):\n",
        "                best_gender_acc = float(line.split(\":\")[1].strip())\n",
        "            elif line.startswith(\"Accent Acc:\"):\n",
        "                best_accent_acc = float(line.split(\":\")[1].strip())\n",
        "            elif line.startswith(\"Step\"):\n",
        "                best_step = int(line.split()[-1])\n",
        "except FileNotFoundError:\n",
        "    pass\n",
        "\n",
        "best_metrics = {\n",
        "    'train_loss': best_t_loss,\n",
        "    'xlsr_train_loss': best_t_xlsr_loss,\n",
        "    'age_train_loss': best_t_age_loss,\n",
        "    'gender_train_loss': best_t_gender_loss,\n",
        "    'accent_train_loss': best_t_accent_loss,\n",
        "\n",
        "    'val_loss': best_v_loss,\n",
        "    'xlsr_val_loss': best_v_xlsr_loss,\n",
        "    'age_val_loss': best_v_age_loss,\n",
        "    'gender_val_loss': best_v_gender_loss,\n",
        "    'accent_val_loss': best_v_accent_loss,\n",
        "\n",
        "    'wer': best_wer,\n",
        "    'age_acc': best_age_acc,\n",
        "    'gender_acc': best_gender_acc,\n",
        "    'accent_acc': best_accent_acc,\n",
        "    'epoch': best_epoch,\n",
        "    'step': best_step\n",
        "}\n",
        "\n",
        "print(best_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZew8A8bhZsi"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import jiwer\n",
        "    jiwer_available = True\n",
        "except ImportError:\n",
        "    jiwer_available = False\n",
        "\n",
        "print(jiwer_available)\n",
        "\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dJvU9c1hZ2_"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}\")\n",
        "    sample = processed_train[0]\n",
        "    train_metrics = train_one_epoch(model, train_loader, optimizer, processor, epoch, lr_scheduler, gradient_accumulation_steps, device)\n",
        "    detailed = (epoch % 10 == 0)\n",
        "    val_metrics = evaluate(model, val_loader, processor, epoch, device, detailed_analysis=detailed)\n",
        "\n",
        "    train_loss = train_metrics['train_loss']\n",
        "    xlsr_train_loss = train_metrics['xlsr_train_loss']\n",
        "    age_train_loss = train_metrics['age_train_loss']\n",
        "    gender_train_loss = train_metrics['gender_train_loss']\n",
        "    accent_train_loss = train_metrics['accent_train_loss']\n",
        "    train_step = train_metrics['step']\n",
        "\n",
        "    val_loss = val_metrics['val_loss']\n",
        "    xlsr_val_loss = val_metrics['xlsr_val_loss']\n",
        "    age_val_loss = val_metrics['age_val_loss']\n",
        "    gender_val_loss = val_metrics['gender_val_loss']\n",
        "    accent_val_loss = val_metrics['accent_val_loss']\n",
        "\n",
        "    wer = val_metrics['wer']\n",
        "    age_acc = val_metrics['age_acc']\n",
        "    gender_acc = val_metrics['gender_acc']\n",
        "    accent_acc = val_metrics['accent_acc']\n",
        "\n",
        "    print(f\"Train Loss: {train_metrics['train_loss']:.4f} | \"\n",
        "          f\"XLSR Train Loss: {train_metrics['xlsr_train_loss']:.4f} | \"\n",
        "          f\"Age Train Loss: {train_metrics['age_train_loss']:.4f} | \"\n",
        "          f\"Gender Train Loss: {train_metrics['gender_train_loss']:.4f} | \"\n",
        "          f\"Accent Train Loss: {train_metrics['accent_train_loss']:.4f} | \"\n",
        "         )\n",
        "    print(f\"Val Loss: {val_metrics['val_loss']:.4f} | \"\n",
        "          f\"XLSR Val Loss: {val_metrics['xlsr_val_loss']:.4f} | \"\n",
        "          f\"Age Val Loss: {val_metrics['age_val_loss']:.4f} | \"\n",
        "          f\"Gender Val Loss: {val_metrics['gender_val_loss']:.4f} | \"\n",
        "          f\"Accent Val Loss: {val_metrics['accent_val_loss']:.4f} | \"\n",
        "          f\"WER: {wer:.4f} | \"\n",
        "          f\"Age Acc: {val_metrics['age_acc']:.4f} | \"\n",
        "          f\"Gender Acc: {val_metrics['gender_acc']:.4f} | \"\n",
        "          f\"Accent Acc: {val_metrics['accent_acc']:.4f} | \"\n",
        "        )\n",
        "\n",
        "    if age_acc > 0.99 and gender_acc > 0.99 and accent_acc > 0.99:\n",
        "        flag = (wer <= best_wer + 1.0)\n",
        "\n",
        "    else:\n",
        "        flag = (\n",
        "            wer <= best_wer + 1.0 and\n",
        "            age_acc >= best_age_acc and\n",
        "            gender_acc >= best_gender_acc and\n",
        "            accent_acc >= best_accent_acc\n",
        "        )\n",
        "\n",
        "    if flag:\n",
        "        is_best = True\n",
        "\n",
        "        best_t_loss = train_loss\n",
        "        best_t_xlsr_loss = xlsr_train_loss\n",
        "        best_t_age_loss = age_train_loss\n",
        "        best_t_gender_loss = gender_train_loss\n",
        "        best_t_accent_loss = accent_train_loss\n",
        "\n",
        "        best_v_loss = val_loss\n",
        "        best_v_xlsr_loss = xlsr_val_loss\n",
        "        best_v_age_loss = age_val_loss\n",
        "        best_v_gender_loss = gender_val_loss\n",
        "        best_v_accent_loss = accent_val_loss\n",
        "\n",
        "        best_wer = wer\n",
        "        best_age_acc = age_acc\n",
        "        best_gender_acc = gender_acc\n",
        "        best_accent_acc = accent_acc\n",
        "        best_epoch = epoch + 1\n",
        "        best_step = train_step\n",
        "\n",
        "        best_metrics = {\n",
        "            'train_loss': best_t_loss,\n",
        "            'xlsr_train_loss': best_t_xlsr_loss,\n",
        "            'age_train_loss': best_t_age_loss,\n",
        "            'gender_train_loss': best_t_gender_loss,\n",
        "            'accent_train_loss': best_t_accent_loss,\n",
        "\n",
        "            'val_loss': best_v_loss,\n",
        "            'xlsr_val_loss': best_v_xlsr_loss,\n",
        "            'age_val_loss': best_v_age_loss,\n",
        "            'gender_val_loss': best_v_gender_loss,\n",
        "            'accent_val_loss': best_v_accent_loss,\n",
        "\n",
        "            'wer': best_wer,\n",
        "            'age_acc': best_age_acc,\n",
        "            'gender_acc': best_gender_acc,\n",
        "            'accent_acc': best_accent_acc,\n",
        "            'epoch': best_epoch,\n",
        "            'step': best_step\n",
        "        }\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"*** Best model saved at epoch {epoch+1} ***\")\n",
        "\n",
        "if is_best:\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"Best model at epoch {best_metrics['epoch']}\\n\\n\")\n",
        "        f.write(f\"Train Loss: {best_metrics['train_loss']:.4f}\\n\")\n",
        "        f.write(f\"XLSR Train Loss: {best_metrics['xlsr_train_loss']:.4f}\\n\")\n",
        "        f.write(f\"Age Train Loss: {best_metrics['age_train_loss']:.4f}\\n\")\n",
        "        f.write(f\"Gender Train Loss: {best_metrics['gender_train_loss']:.4f}\\n\")\n",
        "        f.write(f\"Accent Train Loss: {best_metrics['accent_train_loss']:.4f}\\n\\n\")\n",
        "        f.write(f\"Val Loss: {best_metrics['val_loss']:.4f}\\n\")\n",
        "        f.write(f\"XLSR Val Loss: {best_metrics['xlsr_val_loss']:.4f}\\n\")\n",
        "        f.write(f\"Age Val Loss: {best_metrics['age_val_loss']:.4f}\\n\")\n",
        "        f.write(f\"Gender Val Loss: {best_metrics['gender_val_loss']:.4f}\\n\")\n",
        "        f.write(f\"Accent Val Loss: {best_metrics['accent_val_loss']:.4f}\\n\\n\")\n",
        "        f.write(f\"WER: {best_metrics['wer']:.4f}\\n\")\n",
        "        f.write(f\"Age Acc: {best_metrics['age_acc']:.4f}\\n\")\n",
        "        f.write(f\"Gender Acc: {best_metrics['gender_acc']:.4f}\\n\")\n",
        "        f.write(f\"Accent Acc: {best_metrics['accent_acc']:.4f}\\n\\n\")\n",
        "        f.write(f\"Step: {best_metrics['step']}\\n\")\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFmQn4A7hZ-C"
      },
      "outputs": [],
      "source": [
        "end_time = time.perf_counter()\n",
        "runtime = end_time - start_time\n",
        "if runtime < 60:\n",
        "    print(f\"Total runtime: {runtime:.2f} seconds\")\n",
        "elif runtime < 3600:\n",
        "    print(f\"Total runtime: {runtime/60:.2f} minutes\")\n",
        "else:\n",
        "    print(f\"Total runtime: {runtime/3600:.2f} hours\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpEIS7amhaGU"
      },
      "outputs": [],
      "source": [
        "import jamotools\n",
        "\n",
        "def predict(model, processor, batch, le_age, le_gender, le_accent, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for k in batch:\n",
        "            if isinstance(batch[k], torch.Tensor):\n",
        "                batch[k] = batch[k].to(device)\n",
        "        outputs = model(\n",
        "            input_values=batch['input_values'],\n",
        "            attention_mask=batch['attention_mask']\n",
        "        )\n",
        "        pred_ids = torch.argmax(outputs['logits'], dim=-1)\n",
        "        transcriptions = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "\n",
        "        age_preds = le_age.inverse_transform(outputs['age_logits'].argmax(dim=1).cpu().numpy())\n",
        "        gender_preds = le_gender.inverse_transform(outputs['gender_logits'].argmax(dim=1).cpu().numpy())\n",
        "        accent_preds = le_accent.inverse_transform(outputs['accent_logits'].argmax(dim=1).cpu().numpy())\n",
        "\n",
        "        return transcriptions, age_preds, gender_preds, accent_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zdXuJmmhaNg"
      },
      "outputs": [],
      "source": [
        "# Randomly sample 7 indexes\n",
        "num_samples = 7\n",
        "total_samples = len(test_dataset)\n",
        "random_indices = random.sample(range(total_samples), num_samples)\n",
        "\n",
        "# Sampling and saving raw information\n",
        "samples = [test_dataset[i] for i in random_indices]\n",
        "paths = [sample['path'] for sample in samples]\n",
        "true_texts = [sample['sentence'] for sample in samples]\n",
        "true_ages = [sample['age'] for sample in samples]\n",
        "true_genders = [sample['gender'] for sample in samples]\n",
        "true_accents = [sample['accents'] for sample in samples]\n",
        "\n",
        "processed_samples = [preprocess_function(sample) for sample in samples]\n",
        "batch = collate_fn(processed_samples)\n",
        "\n",
        "model.load_state_dict(torch.load(save_path, map_location=device))\n",
        "transcriptions, age_preds, gender_preds, accent_preds = predict(\n",
        "    model, processor, batch, le_age, le_gender, le_accent, device\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TESTING PHASE - RANDOM SAMPLE PREDICTIONS\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ6nnZX5haYe"
      },
      "outputs": [],
      "source": [
        "for i in range(num_samples):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"Path: {paths[i]}\\n\")\n",
        "    print()\n",
        "    print(\"=== Ground Truth ===\")\n",
        "    print(f\"Text   : {true_texts[i]}\")\n",
        "    print(f\"Age    : {true_ages[i]}\")\n",
        "    print(f\"Gender : {true_genders[i]}\")\n",
        "    print(f\"Accent : {true_accents[i]}\\n\")\n",
        "    print()\n",
        "    print(\"=== Model Prediction ===\")\n",
        "    print(f\"Text   : {jamotools.join_jamos(transcriptions[i])}\")\n",
        "    print(f\"Jamo   : {transcriptions[i]}\")\n",
        "    print(f\"Age    : {age_preds[i]}\")\n",
        "    print(f\"Gender : {gender_preds[i]}\")\n",
        "    print(f\"Accent : {accent_preds[i]}\")\n",
        "\n",
        "    sample_wer = jiwer.wer(true_texts[i], jamotools.join_jamos(transcriptions[i]))\n",
        "    print(f\"WER    : {sample_wer:.4f}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "print(\"Finished!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}